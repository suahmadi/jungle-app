{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b7376a",
   "metadata": {},
   "source": [
    "# import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60ae04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import succeed\n"
     ]
    }
   ],
   "source": [
    "## tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from os import uname\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.indexes.base import Index\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "print(\"import succeed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4fafe",
   "metadata": {},
   "source": [
    "# dataProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16d0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to connect data base and preprocess data\n",
    "\n",
    "#import util\n",
    "DATABASE_ACCESS = \"mongodb+srv://yelshall:yyForever-53611@auth-test.p4buu.mongodb.net/db?retryWrites=true&w=majority\"\n",
    "\n",
    "## connect to the mongo database and return target table as mongo collection\n",
    "## load the database table into np array\n",
    "## take mongo db as arguement\n",
    "## return dataframe\n",
    "def load_data(db,table):\n",
    "    cluster = MongoClient(DATABASE_ACCESS)\n",
    "    return pd.DataFrame(list(cluster[db][table].find()))\n",
    "\n",
    "## return user data as dataframe\n",
    "def get_users():\n",
    "    return load_data(\"db\",\"students\")\n",
    "\n",
    "## return events data as dataframe\n",
    "def get_events():\n",
    "    return load_data(\"db\",\"events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ada9352",
   "metadata": {},
   "source": [
    "# Utility Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "969dc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get events id as numpy array\n",
    "def get_events_id():\n",
    "    return np.array(get_events()[\"_id\"])\n",
    "\n",
    "## get  users id as numpy array\n",
    "def get_users_id(df):\n",
    "    return np.array(df[\"_id\"])\n",
    "## check if a events inside a diction's list\n",
    "\n",
    "def is_in_dict(obj_user,obj_events,D):\n",
    "    return D[obj_user].count(obj_events)==1\n",
    "\n",
    "## use the df to build dislike/like events dictionary\n",
    "def build_liked_dict(df):\n",
    "    return df.set_index(\"_id\").to_dict()[\"interestedEvents\"]\n",
    "\n",
    "## use the df to build dislike events dictionary\n",
    "def build_disliked_dict(df):\n",
    "    return df.set_index(\"_id\").to_dict()[\"unlikedEvents\"]\n",
    "\n",
    "## calculate error of true value vs predicted\n",
    "def sparse_mean_square_error(sparse_ratings, user_embeddings, events_embeddings):\n",
    "    predictions = tf.gather_nd(\n",
    "    tf.matmul(user_embeddings, events_embeddings, transpose_b=True),\n",
    "    sparse_ratings.indices)\n",
    "    loss = tf.losses.mean_squared_error(sparse_ratings.values, predictions)\n",
    "    return loss\n",
    "\n",
    "## tf.SparseTensor representation of the Rating Matrix.\n",
    "## connect to the database and generate two sparse_tensor 1.train 2.test\n",
    "def build_rating_sparse_tensor(df):\n",
    "    events_id = get_events_id()\n",
    "    users_id = get_users_id(df)\n",
    "    ratings = np.zeros((len(users_id),len(events_id)))\n",
    "    for i in range(len(users_id)):\n",
    "        for j in range(len(events_id)):\n",
    "            if(is_in_dict(users_id[i],events_id[j],build_liked_dict(df))):\n",
    "                ratings[i][j] = 1\n",
    "            if(is_in_dict(users_id[i],events_id[j],build_disliked_dict(df))):\n",
    "                ratings[i][j] = -1\n",
    "                \n",
    "#     print((ratings==-1).sum())\n",
    "#     print(len(build_disliked_dict(df)[ObjectId(\"617dd6fb9de5ce231421df11\")]))\n",
    "    print(ratings.shape)\n",
    "    return tf.sparse.from_dense(ratings)\n",
    "\n",
    "def split_dataframe(df, test_rate):\n",
    "    train = df.sample(frac=(1-test_rate))\n",
    "    test = df.sample(frac=test_rate)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "496f105e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 88)\n"
     ]
    }
   ],
   "source": [
    "## test util and dataprocess func\n",
    "df_users = get_users()\n",
    "train,test = split_dataframe(df_users, 0.5)\n",
    "sparse = build_rating_sparse_tensor(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4717e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90b16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8de7af4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# @title CFModel helper class (run this cell)\n",
    "class CFModel(object):\n",
    "  \"\"\"Simple class that represents a collaborative filtering model\"\"\"\n",
    "  def __init__(self, embedding_vars, loss, metrics=None):\n",
    "    \"\"\"\n",
    "    Initializes a CFModel.\n",
    "    Args:\n",
    "      embedding_vars: A dictionary of tf.Variables.\n",
    "      loss: A float Tensor. The loss to optimize.\n",
    "      metrics: optional list of dictionaries of Tensors. The metrics in each\n",
    "      dictionary will be plotted in a separate figure during training.\n",
    "    \"\"\"\n",
    "    self._embedding_vars = embedding_vars\n",
    "    self._loss = loss\n",
    "    self._metrics = metrics\n",
    "    self._embeddings = {k: None for k in embedding_vars}\n",
    "    self._session = None\n",
    "\n",
    "  @property\n",
    "  def embeddings(self):\n",
    "    \"\"\"The embeddings dictionary.\"\"\"\n",
    "    return self._embeddings\n",
    "\n",
    "  def train(self, num_iterations=100, learning_rate=1.0, plot_results=True,\n",
    "            optimizer=tf.train.GradientDescentOptimizer):\n",
    "    \"\"\"Trains the model.\n",
    "    Args:\n",
    "      iterations: number of iterations to run.\n",
    "      learning_rate: optimizer learning rate.\n",
    "      plot_results: whether to plot the results at the end of training.\n",
    "      optimizer: the optimizer to use. Default to GradientDescentOptimizer.\n",
    "    Returns:\n",
    "      The metrics dictionary evaluated at the last iteration.\n",
    "    \"\"\"\n",
    "    with self._loss.graph.as_default():\n",
    "      opt = optimizer(learning_rate)\n",
    "      train_op = opt.minimize(self._loss)\n",
    "      local_init_op = tf.group(\n",
    "          tf.variables_initializer(opt.variables()),\n",
    "          tf.local_variables_initializer())\n",
    "      if self._session is None:\n",
    "        self._session = tf.Session()\n",
    "        with self._session.as_default():\n",
    "          self._session.run(tf.global_variables_initializer())\n",
    "          self._session.run(tf.tables_initializer())\n",
    "          tf.train.start_queue_runners()\n",
    "\n",
    "    with self._session.as_default():\n",
    "      local_init_op.run()\n",
    "      iterations = []\n",
    "      metrics = self._metrics or ({},)\n",
    "      metrics_vals = [collections.defaultdict(list) for _ in self._metrics]\n",
    "\n",
    "      # Train and append results.\n",
    "      for i in range(num_iterations + 1):\n",
    "        _, results = self._session.run((train_op, metrics))\n",
    "        if (i % 10 == 0) or i == num_iterations:\n",
    "          print(\"\\r iteration %d: \" % i + \", \".join(\n",
    "                [\"%s=%f\" % (k, v) for r in results for k, v in r.items()]),\n",
    "                end='')\n",
    "          iterations.append(i)\n",
    "          for metric_val, result in zip(metrics_vals, results):\n",
    "            for k, v in result.items():\n",
    "              metric_val[k].append(v)\n",
    "\n",
    "      for k, v in self._embedding_vars.items():\n",
    "        self._embeddings[k] = v.eval()\n",
    "\n",
    "      if plot_results:\n",
    "        # Plot the metrics.\n",
    "        num_subplots = len(metrics)+1\n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(num_subplots*10, 8)\n",
    "        for i, metric_vals in enumerate(metrics_vals):\n",
    "          ax = fig.add_subplot(1, num_subplots, i+1)\n",
    "          for k, v in metric_vals.items():\n",
    "            ax.plot(iterations, v, label=k)\n",
    "          ax.set_xlim([1, num_iterations])\n",
    "          ax.legend()\n",
    "      return results\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e1c07280",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the model\n",
    "def build_model(train,test, embedding_dim=3, init_stddev=1.):\n",
    "  # Split the ratings DataFrame into train and test.\n",
    "  #train_ratings, test_ratings = split_dataframe(ratings)\n",
    "  # SparseTensor representation of the train and test datasets.\n",
    "  # Initialize the embeddings using a normal distribution.\n",
    "    U = tf.Variable(tf.random_normal(\n",
    "      [train.dense_shape[0], embedding_dim], stddev=init_stddev))\n",
    "    V = tf.Variable(tf.random_normal([train.dense_shape[1], embedding_dim], stddev=init_stddev))\n",
    "    \n",
    "    train_loss = sparse_mean_square_error(train, U, V)\n",
    "    test_loss = sparse_mean_square_error(test, U, V)\n",
    "    \n",
    "    metrics = {\n",
    "      'train_error': train_loss,\n",
    "      'test_error': test_loss\n",
    "    }\n",
    "    embeddings = {\n",
    "      \"user_id\": U,\n",
    "      \"movie_id\": V\n",
    "    }\n",
    "    return CFModel(embeddings, train_loss, [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b6ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3711jvsc74a57bd02c659ff6c79b22a75277c0d8df0de1fc68d2961a8a49d63e07a74b2e76a24577"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
